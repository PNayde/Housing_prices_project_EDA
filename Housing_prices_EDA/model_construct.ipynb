{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè° House Prices - Predictive Modeling\n",
    "\n",
    "## Objective:\n",
    "This notebook builds a predictive model for house prices based on the EDA and feature analysis completed earlier. \n",
    "We aim to select the best features, apply preprocessing, and build regression models to predict `SalePrice`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ Load and Prepare the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assuming the same directory\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Quick check\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Select important features (BASED ON EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt', 'KitchenQual', 'Neighborhood']\n",
    "target = 'SalePrice'\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding Categorical Variables\n",
    "\n",
    "\n",
    "Machine learning models require all input features to be numerical. Since `KitchenQual` and `Neighborhood` are **categorical variables**, we need to **convert them into numerical format** using **one-hot encoding**.\n",
    "\n",
    "### ‚úÖ What is One-Hot Encoding?\n",
    "One-hot encoding creates **binary (0/1) columns** for each unique category in a categorical feature.  \n",
    "For example, if `KitchenQual` has categories like `Ex`, `Gd`, `TA`, and `Fa`, one-hot encoding will create new columns:\n",
    "- `KitchenQual_Gd`, `KitchenQual_TA`, `KitchenQual_Fa`\n",
    "\n",
    "The first category (e.g., `Ex`) is **dropped** to avoid multicollinearity when using linear models ‚Äî this is controlled using `drop_first=True`.\n",
    "\n",
    "### ‚úÖ Why Are We Doing This?\n",
    "- Many machine learning models, especially **Linear Regression**, cannot handle categorical (string) data directly.\n",
    "- Encoding categories numerically allows the model to **interpret and use them as predictors**.\n",
    "\n",
    "### ‚úÖ Note:\n",
    "- We use `drop_first=True` to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 32)\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X, columns=['KitchenQual', 'Neighborhood'], drop_first=True)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Train-Test Split\n",
    "\n",
    "### ‚úÖ Objective:\n",
    "To evaluate the performance of our predictive model, we split the dataset into **training and validation sets**. This allows us to train the model on one portion of the data and test its performance on unseen data (the validation set), ensuring that our model can generalize well to new data.\n",
    "\n",
    "### ‚úÖ Why Do We Split the Data?\n",
    "\n",
    "- **Prevent Overfitting**: If we train and test on the same data, we cannot evaluate how well the model will perform on new, unseen data.\n",
    "- **Model Evaluation**: A validation set allows us to assess the model's performance before using it on the actual test set (from Kaggle or real-world application).\n",
    "\n",
    "### ‚úÖ Split Details:\n",
    "- **Training Set**: 80% of the data (used to train the model).\n",
    "- **Validation Set**: 20% of the data (used to evaluate model performance).\n",
    "- **Random State**: `random_state=42` is used to ensure **reproducibility**, so the split remains the same every time the code is run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Baseline Model: Linear Regression\n",
    "\n",
    "### ‚úÖ Why Start with Linear Regression?\n",
    "\n",
    "Lets start with **Linear Regression** as a **baseline model** because:\n",
    "\n",
    "- **Simple and Interpretable**: Linear Regression is easy to implement and provides interpretable coefficients, which help us understand the relationship between features and the target variable (`SalePrice`).\n",
    "- **Good Benchmark**: It serves as a reference point for evaluating more complex models (like Random Forest or XGBoost). If advanced models don‚Äôt perform significantly better, we may choose to stick with Linear Regression for simplicity.\n",
    "- **Quick to Train**: Linear models are computationally efficient, allowing fast experimentation and evaluation.\n",
    "- **Widely Used in Real Estate**: Linear relationships often exist in housing data (e.g., between size and price), making Linear Regression a natural starting point.\n",
    "\n",
    "### ‚úÖ What will it Measure:\n",
    "- **Root Mean Squared Error (RMSE)**: Measures the average error between predicted and actual prices. Lower RMSE is better.\n",
    "- **R¬≤ Score**: Indicates how much variance in SalePrice is explained by the model (ranges from 0 to 1, higher is better).\n",
    "\n",
    "By starting with Linear Regression, we can establish a **performance benchmark** before trying more advanced machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (1168, 32) (1168,)\n",
      "Validation set: (292, 32) (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y ,test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Baseline Model: Linear Regression\n",
    "\n",
    "### ‚úÖ Why Start with Linear Regression?\n",
    "\n",
    "Lets start with **Linear Regression** as a **baseline model** because:\n",
    "\n",
    "- **Simple and Interpretable**: Linear Regression is easy to implement and provides interpretable coefficients, which help us understand the relationship between features and the target variable (`SalePrice`).\n",
    "- **Good Benchmark**: It serves as a reference point for evaluating more complex models (like Random Forest or XGBoost). If advanced models don‚Äôt perform significantly better, we may choose to stick with Linear Regression for simplicity.\n",
    "- **Quick to Train**: Linear models are computationally efficient, allowing fast experimentation and evaluation.\n",
    "- **Widely Used in Real Estate**: Linear relationships often exist in housing data (e.g., between size and price), making Linear Regression a natural starting point.\n",
    "\n",
    "### ‚úÖ What will it Measure:\n",
    "- **Root Mean Squared Error (RMSE)**: Measures the average error between predicted and actual prices. Lower RMSE is better.\n",
    "- **R¬≤ Score**: Indicates how much variance in SalePrice is explained by the model (ranges from 0 to 1, higher is better).\n",
    "\n",
    "By starting with Linear Regression, we can establish a **performance benchmark** before trying more advanced machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Validation Set: 34787.97\n",
      "R¬≤ Score on Validation Set: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#initialise and train the LR model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#predict on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "#evaluate model performance\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "\n",
    "print(f\"RMSE on Validation Set: {rmse:.2f}\")\n",
    "print(f\"R¬≤ Score on Validation Set: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Feature Engineering\n",
    "\n",
    "### ‚úÖ What is Feature Engineering?\n",
    "\n",
    "**Feature engineering** is the process of creating new features or transforming existing ones to improve the predictive power of a model. It helps uncover hidden patterns and relationships in the data that may not be captured by raw features alone.  \n",
    "\n",
    "Since house prices are influenced by many factors like size, quality, age, and location, **good feature engineering is essential for improving model performance**.\n",
    "\n",
    "### ‚úÖ Why is Feature Engineering Important?\n",
    "\n",
    "- **Improves model accuracy** by providing more relevant information.\n",
    "- **Captures complex relationships** between features (e.g., how size and quality interact to affect price).\n",
    "- Helps models **understand the data better** and generalize to new data.\n",
    "\n",
    "### ‚úÖ Examples of Feature Engineering in House Price Prediction:\n",
    "\n",
    "| Feature Type                  | Example Feature                                                | Why It Helps                                          |\n",
    "|-------------------------------|---------------------------------------------------------------|------------------------------------------------------|\n",
    "| **Combining Features**        | `TotalSF = TotalBsmtSF + 1stFlrSF + 2ndFlrSF`                  | Total square footage is a critical driver of price. |\n",
    "| **Transforming Features**     | `HouseAge = YrSold - YearBuilt`                               | Age of the house can impact its value.              |\n",
    "| **Interaction Features**     | `QualGrLiv = OverallQual * GrLivArea`                        | Large, high-quality homes tend to be more expensive.|\n",
    "| **Garage Space Combination** | `GarageInteraction = GarageArea * GarageCars`                 | Bigger garages that fit more cars can raise value. |\n",
    "| **Binning / Grouping**        | Grouping `HouseAge` into categories (e.g., New, Recent, Old) | Simplifies continuous data into meaningful groups. |\n",
    "\n",
    "### ‚úÖ Why Apply Feature Engineering:\n",
    "\n",
    "- To **enhance the predictive capability** of our model by adding meaningful, domain-informed features.\n",
    "- To potentially **reduce model error (RMSE)** and improve R¬≤.\n",
    "- To prepare the dataset for more advanced models like Random Forest and XGBoost that can leverage these features effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 35)\n",
      "['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt', 'KitchenQual_Fa', 'KitchenQual_Gd', 'KitchenQual_TA', 'Neighborhood_Blueste', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_ClearCr', 'Neighborhood_CollgCr', 'Neighborhood_Crawfor', 'Neighborhood_Edwards', 'Neighborhood_Gilbert', 'Neighborhood_IDOTRR', 'Neighborhood_MeadowV', 'Neighborhood_Mitchel', 'Neighborhood_NAmes', 'Neighborhood_NPkVill', 'Neighborhood_NWAmes', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown', 'Neighborhood_SWISU', 'Neighborhood_Sawyer', 'Neighborhood_SawyerW', 'Neighborhood_Somerst', 'Neighborhood_StoneBr', 'Neighborhood_Timber', 'Neighborhood_Veenker', 'TotalSF', 'HouseAge', 'QualGrLiv']\n"
     ]
    }
   ],
   "source": [
    "# Total square footage of house\n",
    "train_df['TotalSF'] = train_df['TotalBsmtSF'] + train_df['1stFlrSF'] + train_df['2ndFlrSF']\n",
    "\n",
    "# Age of the house at the time it was sold\n",
    "train_df['HouseAge'] = train_df['YrSold'] - train_df['YearBuilt']\n",
    "\n",
    "# Interaction between quality and living area\n",
    "train_df['QualGrLiv'] = train_df['OverallQual'] * train_df['GrLivArea']\n",
    "\n",
    "# Add engineered features to X\n",
    "X['TotalSF'] = train_df['TotalSF']\n",
    "X['HouseAge'] = train_df['HouseAge']\n",
    "X['QualGrLiv'] = train_df['QualGrLiv']\n",
    "\n",
    "# Check updated shape and columns\n",
    "print(X.shape)\n",
    "print(X.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Re-Split the data with the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (1168, 35) (1168,)\n",
      "Validation set: (292, 35) (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Re-split the updated X and y\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check shapes to confirm\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Re-train Linear Regression on the Updated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Validation Set: 33149.77\n",
      "R¬≤ Score on Validation Set: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate performance\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"RMSE on Validation Set: {rmse:.2f}\")\n",
    "print(f\"R¬≤ Score on Validation Set: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Analyze and Sort Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature   Coefficient  Abs_Coefficient\n",
      "22  Neighborhood_NoRidge  67712.864133     67712.864133\n",
      "29  Neighborhood_StoneBr  62894.178795     62894.178795\n",
      "31  Neighborhood_Veenker  58310.505900     58310.505900\n",
      "23  Neighborhood_NridgHt  54241.113613     54241.113613\n",
      "11  Neighborhood_ClearCr  51680.634042     51680.634042\n",
      "5         KitchenQual_Fa -49957.517164     49957.517164\n",
      "7         KitchenQual_TA -48924.965826     48924.965826\n",
      "13  Neighborhood_Crawfor  43503.172514     43503.172514\n",
      "6         KitchenQual_Gd -39931.506530     39931.506530\n",
      "30   Neighborhood_Timber  35557.882153     35557.882153\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe to hold the coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': model.coef_\n",
    "})\n",
    "\n",
    "# Add absolute value of coefficients to measure importance\n",
    "coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "\n",
    "# Sort features by absolute value of coefficient (importance)\n",
    "coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Display top 10 most important features\n",
    "print(coef_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå≤ Advanced Model: Random Forest Regressor\n",
    "\n",
    "### ‚úÖ Why Try Random Forest?\n",
    "\n",
    "After building a simple and interpretable Linear Regression model, we now move to **Random Forest Regressor**, a more advanced machine learning model that can **capture complex, non-linear relationships** in the data.\n",
    "\n",
    "Random Forest is an ensemble method that builds **multiple decision trees** and averages their predictions to improve accuracy and reduce overfitting.\n",
    "\n",
    "\n",
    "### ‚úÖ Why Random Forest?\n",
    "\n",
    "- **Handles Non-Linear Relationships**: Unlike Linear Regression, Random Forest can model complex patterns and interactions between features without needing explicit feature engineering.\n",
    "- **Robust to Outliers and Multicollinearity**: Random Forest naturally handles outliers and doesn't require removing highly correlated variables.\n",
    "- **Feature Importance**: It provides built-in methods to **rank the importance of features**, helping us understand what drives house prices.\n",
    "- **Reduces Overfitting**: By averaging multiple trees, Random Forest creates a **more stable and generalizable model**.\n",
    "- **Minimal Assumptions**: Does not require assumptions about the data distribution (e.g., normality, linearity).\n",
    "\n",
    "### ‚úÖ What Will It Measure:\n",
    "The same as Linear Regression (RMSE and r2)\n",
    "\n",
    "### ‚úÖ Why Use It After Linear Regression?\n",
    "\n",
    "By comparing Random Forest to Linear Regression, we can determine:\n",
    "- If capturing **non-linear relationships** improves our predictions.\n",
    "- If **advanced models** significantly outperform the simple baseline.\n",
    "- Which features Random Forest considers most important (using feature importance analysis).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE on Validation Set: 27808.17\n",
      "Random Forest R¬≤ Score on Validation Set: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate performance\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_val, y_pred_rf))\n",
    "r2_rf = r2_score(y_val, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest RMSE on Validation Set: {rmse_rf:.2f}\")\n",
    "print(f\"Random Forest R¬≤ Score on Validation Set: {r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Model Evaluation and Comparison\n",
    "\n",
    "### üìä Summary of Results:\n",
    "\n",
    "After training and evaluating both **Linear Regression** (baseline model) and **Random Forest Regressor** (advanced model), we observed a significant improvement in performance with Random Forest.\n",
    "\n",
    "| Metric                   | Linear Regression (Baseline) | Random Forest Regressor (Advanced) | Improvement          |\n",
    "|-------------------------|-----------------------------|------------------------------------|---------------------|\n",
    "| **RMSE (Validation)**    | 33,149.77                   | **27,808.17**                      | ‚úÖ Lower error ‚Äî better predictions |\n",
    "| **R¬≤ Score (Validation)**| 0.86                        | **0.90**                           | ‚úÖ More variance explained (better fit) |\n",
    "\n",
    "\n",
    "### ‚úÖ Key Takeaways:\n",
    "\n",
    "- **Random Forest Regressor** outperforms Linear Regression significantly, achieving **lower RMSE and higher R¬≤**.\n",
    "- The **non-linear nature** of Random Forest allows it to capture **complex relationships and interactions** between features that Linear Regression cannot.\n",
    "- The model now explains **90% of the variance in house prices**, which is a very strong performance.\n",
    "- This confirms that using advanced models combined with carefully engineered features like `TotalSF`, `HouseAge`, and `QualGrLiv` **greatly enhances predictive accuracy**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   2.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.7s\n",
      "Best Parameters Found: {'n_estimators': 300, 'min_samples_split': 2, 'max_features': 'log2', 'max_depth': 20}\n",
      "Tuned Random Forest RMSE on Validation Set: 28100.45\n",
      "Tuned Random Forest R¬≤ Score on Validation Set: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300,500],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf=RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "  estimator=rf,\n",
    "  param_distributions=param_grid,\n",
    "  n_iter=50,\n",
    "  cv=5,\n",
    "  verbose=2,\n",
    "  random_state=42,\n",
    "  n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Randomized Search on training data\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters Found:\", rf_random_search.best_params_)\n",
    "\n",
    "# Best model from search\n",
    "best_rf = rf_random_search.best_estimator_\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_rf_best = best_rf.predict(X_val)\n",
    "\n",
    "# Evaluate performance\n",
    "rmse_rf_best = np.sqrt(mean_squared_error(y_val, y_pred_rf_best))\n",
    "r2_rf_best = r2_score(y_val, y_pred_rf_best)\n",
    "\n",
    "print(f\"Tuned Random Forest RMSE on Validation Set: {rmse_rf_best:.2f}\")\n",
    "print(f\"Tuned Random Forest R¬≤ Score on Validation Set: {r2_rf_best:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå≤ Hyperparameter Tuning: Random Forest Regressor\n",
    "\n",
    "### ‚úÖ Objective:\n",
    "After building a baseline Random Forest model, we performed **hyperparameter tuning using RandomizedSearchCV** to find the best combination of settings that optimize model performance. This step helps improve accuracy and ensures our model is neither underfitting nor overfitting.\n",
    "\n",
    "### ‚úÖ Parameters Tuned:\n",
    "\n",
    "| Hyperparameter              | Purpose                                                     |\n",
    "|----------------------------|------------------------------------------------------------|\n",
    "| `n_estimators`              | Number of trees in the forest. More trees = better stability, but slower. |\n",
    "| `max_depth`                 | Maximum depth of each tree. Controls tree complexity and prevents overfitting. |\n",
    "| `min_samples_split`         | Minimum samples needed to split a node. Controls when trees should grow deeper. |\n",
    "| `max_features`              | Number of features to consider when looking for best split. Controls randomness and diversity of trees. |\n",
    "\n",
    "\n",
    "### ‚úÖ Best Hyperparameters Found:\n",
    "\n",
    "```python\n",
    "{'n_estimators': 300, 'min_samples_split': 2, 'max_features': 'log2', 'max_depth': 20}\n",
    "```\n",
    "\n",
    "\n",
    "### ‚úÖ Performance on Validation Set:\n",
    "\n",
    "| Metric                | Value                      |\n",
    "|----------------------|----------------------------|\n",
    "| **RMSE (Validation)** | **28,100.45**               |\n",
    "| **R¬≤ Score**          | **0.90**                   |\n",
    "\n",
    "\n",
    "### ‚úÖ Key Takeaways:\n",
    "\n",
    "- **Strong performance**: The tuned Random Forest explains **90% of the variance** in house prices.\n",
    "- **Good accuracy**: Average error of approximately \\$28,100, which is reasonable for real estate prices.\n",
    "- **Tuned model is better than default model** and more stable.\n",
    "- **Feature subset (`max_features='log2'`)** improves model diversity and reduces overfitting compared to using all features.\n",
    "- **Moderate depth (`max_depth=20`)** balances complexity and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=20, max_features=&#x27;log2&#x27;, n_estimators=300,\n",
       "                      random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=20, max_features=&#x27;log2&#x27;, n_estimators=300,\n",
       "                      random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=20, max_features='log2', n_estimators=300,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Final model with best hyperparameters found\n",
    "final_rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    min_samples_split=2,\n",
    "    max_features='log2',\n",
    "    max_depth=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on the entire training data\n",
    "final_rf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Feature engineering on test set (same as training set)\n",
    "test_df['TotalSF'] = test_df['TotalBsmtSF'] + test_df['1stFlrSF'] + test_df['2ndFlrSF']\n",
    "test_df['HouseAge'] = test_df['YrSold'] - test_df['YearBuilt']\n",
    "test_df['QualGrLiv'] = test_df['OverallQual'] * test_df['GrLivArea']\n",
    "\n",
    "# Select same features as used in training\n",
    "test_X = test_df[['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt', 'KitchenQual', 'Neighborhood',\n",
    "                  'TotalSF', 'HouseAge', 'QualGrLiv']]\n",
    "\n",
    "# One-hot encoding (align columns with training set)\n",
    "test_X = pd.get_dummies(test_X, drop_first=True)\n",
    "\n",
    "# Align columns of test set to training set\n",
    "test_X = test_X.reindex(columns=X.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "test_preds = final_rf.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_df['Id'],  # Make sure 'Id' column is present in test.csv\n",
    "    'SalePrice': test_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
